# simulation/environment.py
import asyncio
from datetime import datetime
from typing import List, Dict

from skyfield.api import Topos

from config import MIN_MODELS_FOR_AGGREGATION, AGGREGATION_STALENESS_THRESHOLD
from ml.model import PyTorchModel
from ml.training import evaluate_model, fed_avg
from utils.logging_setup import KST

class IoTCluster:
    """ë°ì´í„° ì†ŒìŠ¤ê°€ ë˜ëŠ” IoT í´ëŸ¬ìŠ¤í„°ë¥¼ ë‚˜íƒ€ë‚´ëŠ” í´ë˜ìŠ¤"""
    def __init__(self, name: str, latitude: float, longitude: float, elevation: int, sim_logger=None):
        self.name = name
        self.topos = Topos(latitude_degrees=latitude, longitude_degrees=longitude, elevation_m=elevation)
        self.logger = sim_logger
        self.logger.info(f"IoT í´ëŸ¬ìŠ¤í„° '{self.name}' ìƒì„± ì™„ë£Œ.")

class GroundStation:
    """
    ì§€ìƒêµ­ í´ë˜ìŠ¤.
    - ìœ„ì„±ê³¼ì˜ í†µì‹ (AOS/LOS)ì„ ê´€ë¦¬
    - í´ëŸ¬ìŠ¤í„° ëª¨ë¸ì„ ìˆ˜ì‹ í•˜ê³  ê¸€ë¡œë²Œ ëª¨ë¸ì„ ì·¨í•©(Aggregation)
    - ì—…ë°ì´íŠ¸ëœ ê¸€ë¡œë²Œ ëª¨ë¸ì„ ìœ„ì„±ì— ì „íŒŒ
    """
    def __init__(self, name: str, latitude: float, longitude: float, elevation: int, initial_model: PyTorchModel, 
                 eval_infra: dict, threshold_deg: float = 10.0,
                 min_models_agg: int = MIN_MODELS_FOR_AGGREGATION, 
                 staleness_th: int = AGGREGATION_STALENESS_THRESHOLD):
        self.name = name
        self.topos = Topos(latitude_degrees=latitude, longitude_degrees=longitude, elevation_m=elevation)
        self.threshold_deg = threshold_deg
        self.global_model = initial_model
        self.received_models_buffer: List[PyTorchModel] = []
        self._comm_status: Dict[int, bool] = {}
        self.min_models_for_aggregation = min_models_agg
        self.staleness_threshold = staleness_th
        self.logger = eval_infra['sim_logger']
        self.perf_logger = eval_infra['perf_logger']
        self.test_loader = eval_infra['test_loader']
        self.device = eval_infra['device']
        self.logger.info(f"ì§€ìƒêµ­ '{self.name}' ìƒì„± ì™„ë£Œ. ê¸€ë¡œë²Œ ëª¨ë¸ ë²„ì „: {self.global_model.version}")
        self.logger.info(f"  - Aggregation ì •ì±…: ìµœì†Œ ëª¨ë¸ {self.min_models_for_aggregation}ê°œ, ë²„ì „ í—ˆìš©ì¹˜ {self.staleness_threshold}")

    async def run(self, clock: 'SimulationClock', satellites: Dict[int, 'Satellite']):
        self.logger.info(f"ì§€ìƒêµ­ '{self.name}' ìš´ì˜ ì‹œì‘.")
        asyncio.create_task(self.periodic_aggregation_task())
        while True:
            current_ts = clock.get_time_ts()
            for sat_id, sat in satellites.items():
                if not hasattr(sat, 'cluster_members'): continue # MasterSatelliteë§Œ ìƒëŒ€
                
                elevation = (sat.satellite_obj - self.topos).at(current_ts).altaz()[0].degrees
                prev_visible = self._comm_status.get(sat_id, False)
                visible_now = elevation >= self.threshold_deg

                if visible_now:
                    if not prev_visible: # First moment of contact (AOS)
                        self.logger.info(f"ğŸ“¡ [AOS] {self.name} <-> MasterSAT {sat_id} í†µì‹  ì‹œì‘ (ê³ ë„ê°: {elevation:.2f}Â°)")
                        sat.state = 'COMMUNICATING_GS'
                    
                    # 1. ìˆ˜ì‹  ë¨¼ì € ì‹œë„
                    if sat.model_ready_to_upload:
                        await self.receive_model_from_satellite(sat)
                        # ìˆ˜ì‹  ì§í›„ ë°”ë¡œ ì§‘ê³„ ì‹œë„í•˜ì—¬ ëª¨ë¸ ì¦‰ì‹œ ì—…ë°ì´íŠ¸
                        await self.try_aggregate_and_update()
                    
                    # 2. ê·¸ ë‹¤ìŒ ì†¡ì‹ 
                    await self.send_model_to_satellite(sat)

                elif prev_visible and not visible_now: # LOS
                    self.logger.info(f"ğŸ“¡ [LOS] {self.name} <-> MasterSAT {sat_id} í†µì‹  ì¢…ë£Œ (ê³ ë„ê°: {elevation:.2f}Â°)")
                    sat.state = 'IDLE'
                
                self._comm_status[sat_id] = visible_now

            await asyncio.sleep(clock.real_interval)

    async def send_model_to_satellite(self, satellite: 'MasterSatellite'):
        self.logger.info(f"  ğŸ“¤ {self.name} -> MasterSAT {satellite.sat_id}: ê¸€ë¡œë²Œ ëª¨ë¸ ì „ì†¡ (ë²„ì „ {self.global_model.version})")
        await satellite.receive_global_model(self.global_model)

    async def receive_model_from_satellite(self, satellite: 'MasterSatellite'):
        cluster_model = await satellite.send_local_model()
        if cluster_model:
            self.logger.info(f"  ğŸ“¥ {self.name} <- MasterSAT {satellite.sat_id}: í´ëŸ¬ìŠ¤í„° ëª¨ë¸ ìˆ˜ì‹  ì™„ë£Œ (ë²„ì „ {cluster_model.version}, í•™ìŠµì: {cluster_model.trained_by})")
            self.received_models_buffer.append(cluster_model)

    async def periodic_aggregation_task(self):
        """ì£¼ê¸°ì ìœ¼ë¡œ Aggregationì„ ì‹œë„í•˜ëŠ” ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…"""
        while True:
            await asyncio.sleep(30)
            await self.try_aggregate_and_update()
            
    async def try_aggregate_and_update(self):
        """Aggregation ì¡°ê±´ í™•ì¸ ë° ìˆ˜í–‰"""
        if len(self.received_models_buffer) < self.min_models_for_aggregation: return
        
        try:
            max_version_in_buffer = max(model.version for model in self.received_models_buffer)
        except ValueError:
            return # ë²„í¼ê°€ ë¹„ì—ˆì„ ê²½ìš°

        if max_version_in_buffer < self.global_model.version: return

        version_lower_bound = max_version_in_buffer - self.staleness_threshold
        models_to_aggregate = [m for m in self.received_models_buffer if m.version >= version_lower_bound]
        
        if len(models_to_aggregate) < self.min_models_for_aggregation: return

        self.logger.info(f"âœ¨ [{self.name} Aggregation] {len(models_to_aggregate)}ê°œ ëª¨ë¸(v >= {version_lower_bound})ê³¼ ê¸°ì¡´ ê¸€ë¡œë²Œ ëª¨ë¸(v{self.global_model.version}) ì·¨í•© ì‹œì‘...")
        
        state_dicts_to_avg = [self.global_model.model_state_dict] + [m.model_state_dict for m in models_to_aggregate]
        new_state_dict = fed_avg(state_dicts_to_avg)
        
        new_version = self.global_model.version + 1 # ë²„ì „ì—…
        all_contributors = list(set(self.global_model.trained_by + [p for model in models_to_aggregate for p in model.trained_by]))
        self.global_model = PyTorchModel(version=new_version, model_state_dict=new_state_dict, trained_by=all_contributors)
        self.logger.info(f"âœ¨ [{self.name} Aggregation] ìƒˆë¡œìš´ ê¸€ë¡œë²Œ ëª¨ë¸ ìƒì„± ì™„ë£Œ! (ë²„ì „ {self.global_model.version})")

        accuracy, loss = evaluate_model(self.global_model.model_state_dict, self.test_loader, self.device)
        self.logger.info(f"  ğŸ§ª [Global Test] Owner: {self.name}, Version: {self.global_model.version}, Accuracy: {accuracy:.2f}%, Loss: {loss:.4f}")
        self.perf_logger.info(f"{datetime.now(KST).isoformat()},GLOBAL_TEST,{self.name},{self.global_model.version},N/A,{accuracy:.4f},{loss:.6f}")

        aggregated_model_ids = {id(m) for m in models_to_aggregate}
        self.received_models_buffer = [m for m in self.received_models_buffer if id(m) not in aggregated_model_ids]
        
        if self.received_models_buffer:
            try:
                current_max_version = max(m.version for m in self.received_models_buffer)
                cleanup_lower_bound = current_max_version - self.staleness_threshold
                models_to_discard = [m for m in self.received_models_buffer if m.version < cleanup_lower_bound]
                if models_to_discard:
                    discard_versions = {m.version for m in models_to_discard}
                    self.logger.info(f"  ğŸ—‘ï¸  [{self.name}] {len(models_to_discard)}ê°œì˜ ì˜¤ë˜ëœ ëª¨ë¸ ì •ë¦¬ (ë²„ì „: {discard_versions})")
                    discard_model_ids = {id(m) for m in models_to_discard}
                    self.received_models_buffer = [m for m in self.received_models_buffer if id(m) not in discard_model_ids]
            except ValueError: pass
